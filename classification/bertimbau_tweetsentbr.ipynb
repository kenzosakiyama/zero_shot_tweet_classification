{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bertimbau_tweetsentbr_v2_usando_datasets.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1tiDPZNk9xuAP48cSo8RU33slq7rj1qTz","authorship_tag":"ABX9TyNVfF5v0jRS2vtugHjHBLVx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"a5577b031abd405c95779f0a2ca9415d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f4b3557603304de4a921d997f4d5b70c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_dcfe9d73cacd437eb84175b49f48c573","IPY_MODEL_23217fdb526149c6b1dcef33d2ebde21","IPY_MODEL_329e453b7b5748d291aa4257cc0d587c"]}},"f4b3557603304de4a921d997f4d5b70c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dcfe9d73cacd437eb84175b49f48c573":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2878366f82be4cb6813e08d27df8d501","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_12e6634931f042df8d8279b56241c345"}},"23217fdb526149c6b1dcef33d2ebde21":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2105085c50d948998070e1942dd423b4","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":10,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":10,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_77990181c0384293a30244f719116328"}},"329e453b7b5748d291aa4257cc0d587c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4ee8d903123046c690ed0193c2fb2250","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 10/10 [00:00&lt;00:00, 15.85ba/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7fae2055425141c8892ad6ddd6adca31"}},"2878366f82be4cb6813e08d27df8d501":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"12e6634931f042df8d8279b56241c345":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2105085c50d948998070e1942dd423b4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"77990181c0384293a30244f719116328":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4ee8d903123046c690ed0193c2fb2250":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7fae2055425141c8892ad6ddd6adca31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lDPG_jjgWV2X","executionInfo":{"status":"ok","timestamp":1630005977229,"user_tz":240,"elapsed":7686,"user":{"displayName":"Kenzo Miranda Sakiyama","photoUrl":"","userId":"17190914206091993570"}},"outputId":"19aafa78-a37f-4505-af90-1ea7afb28c27"},"source":["!pip3 install transformers\n","!pip3 install datasets"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.9.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n","Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (1.11.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n","Requirement already satisfied: tqdm>=4.42 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.62.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.6.4)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (2.0.2)\n","Requirement already satisfied: huggingface-hub<0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.0.12)\n","Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2021.7.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.7.4.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.5.30)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.5.0)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Jh7xutVM2R33","executionInfo":{"status":"ok","timestamp":1630005977233,"user_tz":240,"elapsed":25,"user":{"displayName":"Kenzo Miranda Sakiyama","photoUrl":"","userId":"17190914206091993570"}}},"source":["binary = False"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4rACU0FMYEnT"},"source":["# Preparando Dataset"]},{"cell_type":"code","metadata":{"id":"T8VsrezgcIfl","executionInfo":{"status":"ok","timestamp":1630005978002,"user_tz":240,"elapsed":789,"user":{"displayName":"Kenzo Miranda Sakiyama","photoUrl":"","userId":"17190914206091993570"}}},"source":["from datasets import Dataset\n","import pandas as pd"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"3jc34_imYL2T","executionInfo":{"status":"ok","timestamp":1630005978005,"user_tz":240,"elapsed":48,"user":{"displayName":"Kenzo Miranda Sakiyama","photoUrl":"","userId":"17190914206091993570"}}},"source":["data_df = pd.read_csv(\"/content/drive/MyDrive/Mestrado/transformers/data/tweetsentbr_train.csv\", index_col=0)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"CH8IJ1YI2s1H","executionInfo":{"status":"ok","timestamp":1630005978008,"user_tz":240,"elapsed":47,"user":{"displayName":"Kenzo Miranda Sakiyama","photoUrl":"","userId":"17190914206091993570"}}},"source":["if binary:\n","  data_df = data_df[data_df[\"label\"] != 0]\n","  data_df[\"label\"] -= 1 # 0 será a classe positiva, 1 será a classe negativa"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"WsY3P5SYcOhW","executionInfo":{"status":"ok","timestamp":1630005978013,"user_tz":240,"elapsed":38,"user":{"displayName":"Kenzo Miranda Sakiyama","photoUrl":"","userId":"17190914206091993570"}}},"source":["ds = Dataset.from_pandas(data_df)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"omwPDs9Xcccr","executionInfo":{"status":"ok","timestamp":1630005978016,"user_tz":240,"elapsed":38,"user":{"displayName":"Kenzo Miranda Sakiyama","photoUrl":"","userId":"17190914206091993570"}},"outputId":"390c7543-be4f-4e61-9158-0aefaa5d7ad8"},"source":["ds"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['label', 'text', '__index_level_0__'],\n","    num_rows: 9849\n","})"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"PTYe4yCecW4i"},"source":["# Carregando modelos"]},{"cell_type":"code","metadata":{"id":"mP9phfbicTj1","executionInfo":{"status":"ok","timestamp":1630005981964,"user_tz":240,"elapsed":3977,"user":{"displayName":"Kenzo Miranda Sakiyama","photoUrl":"","userId":"17190914206091993570"}}},"source":["from transformers import BertTokenizerFast, BertForSequenceClassification\n","import torch.nn as nn"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xLFpZ4SDdneM","executionInfo":{"status":"ok","timestamp":1630006003024,"user_tz":240,"elapsed":21064,"user":{"displayName":"Kenzo Miranda Sakiyama","photoUrl":"","userId":"17190914206091993570"}},"outputId":"c2ccc5d0-e202-4f62-9000-e0e3982a0803"},"source":["model = \"neuralmind/bert-base-portuguese-cased\"\n","tokenizer = BertTokenizerFast.from_pretrained(model)\n","model = BertForSequenceClassification.from_pretrained(model, num_labels=2 if binary else 3)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yExFa8OejS1m","executionInfo":{"status":"ok","timestamp":1630006003029,"user_tz":240,"elapsed":71,"user":{"displayName":"Kenzo Miranda Sakiyama","photoUrl":"","userId":"17190914206091993570"}},"outputId":"87c0aa24-7b66-484e-f25e-2723e0c518c0"},"source":["model.config"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertConfig {\n","  \"_name_or_path\": \"neuralmind/bert-base-portuguese-cased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"directionality\": \"bidi\",\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_fc_size\": 768,\n","  \"pooler_num_attention_heads\": 12,\n","  \"pooler_num_fc_layers\": 3,\n","  \"pooler_size_per_head\": 128,\n","  \"pooler_type\": \"first_token_transform\",\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.9.2\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 29794\n","}"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"lUpAV8rnijDq","executionInfo":{"status":"ok","timestamp":1630006003034,"user_tz":240,"elapsed":62,"user":{"displayName":"Kenzo Miranda Sakiyama","photoUrl":"","userId":"17190914206091993570"}}},"source":["# Atualizando a camada de classificador final. É preciso ajustar os parametros para o Trainer funcionar\n","# NÃO é preciso definir tudo isto caso seja especificado o num_labels no método from_pretrained\n","# model.classifier = nn.Linear(in_features=model.config.hidden_size, out_features=n_classes)\n","# model.num_labels = n_classes"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"k8bPa4P6meP-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630006003039,"user_tz":240,"elapsed":62,"user":{"displayName":"Kenzo Miranda Sakiyama","photoUrl":"","userId":"17190914206091993570"}},"outputId":"bff75dfe-d1b2-466e-c2cb-27420602618f"},"source":["model"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(29794, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",")"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"7UkE1TRPQkYY"},"source":["# Analisando número de tokens no conjunto de dados inteiro"]},{"cell_type":"code","metadata":{"id":"aNIqaU3RRa5S","executionInfo":{"status":"ok","timestamp":1630006003042,"user_tz":240,"elapsed":51,"user":{"displayName":"Kenzo Miranda Sakiyama","photoUrl":"","userId":"17190914206091993570"}}},"source":["def get_num_tokens(text: str) -> int:\n","  return len(tokenizer.encode(text))"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vvewyel9SUvD","executionInfo":{"status":"ok","timestamp":1630006004544,"user_tz":240,"elapsed":1548,"user":{"displayName":"Kenzo Miranda Sakiyama","photoUrl":"","userId":"17190914206091993570"}}},"source":["data_df[\"num_tokens\"] = data_df[\"text\"].apply(get_num_tokens)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"mHM-OrCwSdwJ","executionInfo":{"status":"ok","timestamp":1630006004555,"user_tz":240,"elapsed":43,"user":{"displayName":"Kenzo Miranda Sakiyama","photoUrl":"","userId":"17190914206091993570"}},"outputId":"8b3a3e92-8540-4338-ad50-52b31dde9580"},"source":["data_df.head()"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>text</th>\n","      <th>num_tokens</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>5689</th>\n","      <td>1</td>\n","      <td>Simplesmente magnífica @fbbreal no Video Show ...</td>\n","      <td>33</td>\n","    </tr>\n","    <tr>\n","      <th>5386</th>\n","      <td>1</td>\n","      <td>Saiu, mas saiu ahazando. Master Chef BR</td>\n","      <td>16</td>\n","    </tr>\n","    <tr>\n","      <th>869</th>\n","      <td>1</td>\n","      <td>Já tô pronta pro Master Chef BR</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>5432</th>\n","      <td>1</td>\n","      <td>Muito amor por é o tchan Altas Horas</td>\n","      <td>12</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>1</td>\n","      <td>QUE PROGRAMA INCRÍVEL O @SBTTheNoite FEZ HOJE!...</td>\n","      <td>60</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      label                                               text  num_tokens\n","5689      1  Simplesmente magnífica @fbbreal no Video Show ...          33\n","5386      1            Saiu, mas saiu ahazando. Master Chef BR          16\n","869       1                    Já tô pronta pro Master Chef BR          11\n","5432      1               Muito amor por é o tchan Altas Horas          12\n","24        1  QUE PROGRAMA INCRÍVEL O @SBTTheNoite FEZ HOJE!...          60"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Xop_33gShAS","executionInfo":{"status":"ok","timestamp":1630006004561,"user_tz":240,"elapsed":31,"user":{"displayName":"Kenzo Miranda Sakiyama","photoUrl":"","userId":"17190914206091993570"}},"outputId":"2af8f385-e3e6-406b-9701-9a5e4dd26398"},"source":["data_df[\"num_tokens\"].describe()"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["count    9849.000000\n","mean       23.718652\n","std         9.820523\n","min         6.000000\n","25%        16.000000\n","50%        22.000000\n","75%        30.000000\n","max        95.000000\n","Name: num_tokens, dtype: float64"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":286},"id":"nwSy-uhwSg-G","executionInfo":{"status":"ok","timestamp":1630006005410,"user_tz":240,"elapsed":872,"user":{"displayName":"Kenzo Miranda Sakiyama","photoUrl":"","userId":"17190914206091993570"}},"outputId":"2fa18e24-eb68-4900-f108-bf10ec33ffc1"},"source":["data_df[\"num_tokens\"].hist(bins=30)"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f395a1a8390>"]},"metadata":{},"execution_count":18},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"Cu0JZOAhd7_w"},"source":["# Pre-processamento de Datasets"]},{"cell_type":"code","metadata":{"id":"xPWjDUH2deuR","executionInfo":{"status":"ok","timestamp":1630006005413,"user_tz":240,"elapsed":56,"user":{"displayName":"Kenzo Miranda Sakiyama","photoUrl":"","userId":"17190914206091993570"}}},"source":["from transformers import DataCollatorWithPadding"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"5ir27h0xcmUI","executionInfo":{"status":"ok","timestamp":1630006005415,"user_tz":240,"elapsed":55,"user":{"displayName":"Kenzo Miranda Sakiyama","photoUrl":"","userId":"17190914206091993570"}}},"source":["def tokenizer_function(example):\n","  # Em caso de uma tarefa de classificação de pares de texto, modificar este valor de retorno\n","  # truncation=True, padding=\"max_length\", max_length=123 para truncar e padronizar os tamanhos de tokens!!!\n","  return tokenizer(\n","      example[\"text\"], truncation=True\n","  )"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":86,"referenced_widgets":["a5577b031abd405c95779f0a2ca9415d","f4b3557603304de4a921d997f4d5b70c","dcfe9d73cacd437eb84175b49f48c573","23217fdb526149c6b1dcef33d2ebde21","329e453b7b5748d291aa4257cc0d587c","2878366f82be4cb6813e08d27df8d501","12e6634931f042df8d8279b56241c345","2105085c50d948998070e1942dd423b4","77990181c0384293a30244f719116328","4ee8d903123046c690ed0193c2fb2250","7fae2055425141c8892ad6ddd6adca31"]},"id":"stgVH7H2c-mA","executionInfo":{"status":"ok","timestamp":1630006006008,"user_tz":240,"elapsed":635,"user":{"displayName":"Kenzo Miranda Sakiyama","photoUrl":"","userId":"17190914206091993570"}},"outputId":"d87f3abe-2655-4da6-acfe-2416e13fcb8e"},"source":["# Tokenizando todos os elementos do conjunto de dados em batches\n","ds = ds.map(tokenizer_function, batched=True)"],"execution_count":21,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a5577b031abd405c95779f0a2ca9415d","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/10 [00:00<?, ?ba/s]"]},"metadata":{}},{"output_type":"stream","text":["Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"qyrSEjnbdEVc","executionInfo":{"status":"ok","timestamp":1630006006010,"user_tz":240,"elapsed":31,"user":{"displayName":"Kenzo Miranda Sakiyama","photoUrl":"","userId":"17190914206091993570"}}},"source":["# Mantendo apenas colunas cujos nomes coincidam com os métodos forward dos transformers\n","ds = ds.remove_columns(column_names=[\"text\", \"__index_level_0__\"])\n","ds = ds.rename_column(\"label\", \"labels\")\n","ds = ds.with_format(\"torch\")"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"MnPDLaQGdSoq","executionInfo":{"status":"ok","timestamp":1630006006012,"user_tz":240,"elapsed":30,"user":{"displayName":"Kenzo Miranda Sakiyama","photoUrl":"","userId":"17190914206091993570"}}},"source":["# Split de treino e teste (20%)\n","ds = ds.train_test_split(0.1)"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"92nWl1g0dZZ_","executionInfo":{"status":"ok","timestamp":1630006006014,"user_tz":240,"elapsed":30,"user":{"displayName":"Kenzo Miranda Sakiyama","photoUrl":"","userId":"17190914206091993570"}},"outputId":"600c9bef-ebdc-4c7c-d18e-733e6f9a5f61"},"source":["ds"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['attention_mask', 'input_ids', 'labels', 'token_type_ids'],\n","        num_rows: 8864\n","    })\n","    test: Dataset({\n","        features: ['attention_mask', 'input_ids', 'labels', 'token_type_ids'],\n","        num_rows: 985\n","    })\n","})"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"GlZXmH-xddW6","executionInfo":{"status":"ok","timestamp":1630006006016,"user_tz":240,"elapsed":28,"user":{"displayName":"Kenzo Miranda Sakiyama","photoUrl":"","userId":"17190914206091993570"}}},"source":["# Collator para Dynamic Padding\n","collator = DataCollatorWithPadding(tokenizer, padding=\"longest\")"],"execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GvEYK0M5ecfH"},"source":["# Configurando Trainer"]},{"cell_type":"code","metadata":{"id":"w8Exwa5TebcJ","executionInfo":{"status":"ok","timestamp":1630006006017,"user_tz":240,"elapsed":28,"user":{"displayName":"Kenzo Miranda Sakiyama","photoUrl":"","userId":"17190914206091993570"}}},"source":["from transformers import Trainer, TrainingArguments, get_cosine_schedule_with_warmup, AdamW\n","from datasets import load_metric\n","import math"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"7qf6N__Geh-l","executionInfo":{"status":"ok","timestamp":1630006006018,"user_tz":240,"elapsed":29,"user":{"displayName":"Kenzo Miranda Sakiyama","photoUrl":"","userId":"17190914206091993570"}}},"source":["bs = 64\n","epochs = 5\n","lr = 2e-5\n","warmup_steps = math.ceil((len(ds[\"train\"])/bs) * epochs * 0.1) #10% of train data for warm-up\n","train_steps = int(epochs * len(ds[\"train\"])/bs)"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cDj3aYrdevuM","executionInfo":{"status":"ok","timestamp":1630006006020,"user_tz":240,"elapsed":30,"user":{"displayName":"Kenzo Miranda Sakiyama","photoUrl":"","userId":"17190914206091993570"}},"outputId":"786cf868-404d-4485-ddc2-924961f91fed"},"source":["warmup_steps, train_steps"],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(70, 692)"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"FusH0lqPeydx","executionInfo":{"status":"ok","timestamp":1630006006021,"user_tz":240,"elapsed":25,"user":{"displayName":"Kenzo Miranda Sakiyama","photoUrl":"","userId":"17190914206091993570"}}},"source":["import numpy as np\n","from sklearn.metrics import classification_report\n","from datasets import load_metric\n","\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    predictions = np.argmax(logits, axis=-1)\n","    metrics_dict = classification_report(labels, predictions, output_dict=True)\n","\n","    return {\n","        \"accuracy\": metrics_dict[\"accuracy\"],\n","        \"precision\": metrics_dict[\"macro avg\"][\"precision\"],\n","        \"recall\": metrics_dict[\"macro avg\"][\"recall\"],\n","        \"f1\": metrics_dict[\"macro avg\"][\"f1-score\"]\n","    }\n"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"SOBpncfLbAQN","executionInfo":{"status":"ok","timestamp":1630006006489,"user_tz":240,"elapsed":492,"user":{"displayName":"Kenzo Miranda Sakiyama","photoUrl":"","userId":"17190914206091993570"}}},"source":["optimizer = AdamW(model.parameters(), lr=lr) \n","scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=train_steps, num_cycles=0.5)"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"la2JUzFQ4Gu7","executionInfo":{"status":"ok","timestamp":1630006006490,"user_tz":240,"elapsed":22,"user":{"displayName":"Kenzo Miranda Sakiyama","photoUrl":"","userId":"17190914206091993570"}}},"source":["output_dir = '/content/drive/MyDrive/Mestrado/transformers/trained_models/bertimbau_tweetsentbr/binary' if binary else \\\n","             '/content/drive/MyDrive/Mestrado/transformers/trained_models/bertimbau_tweetsentbr/all_classes'"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"zTr9bVRG4bc6","executionInfo":{"status":"ok","timestamp":1630006006494,"user_tz":240,"elapsed":24,"user":{"displayName":"Kenzo Miranda Sakiyama","photoUrl":"","userId":"17190914206091993570"}},"outputId":"06f63cf4-c52b-42ac-ea0c-692e261366f3"},"source":["output_dir"],"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/Mestrado/transformers/trained_models/bertimbau_tweetsentbr/all_classes'"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"WUwiB8mKfgqd","executionInfo":{"status":"ok","timestamp":1630006006496,"user_tz":240,"elapsed":22,"user":{"displayName":"Kenzo Miranda Sakiyama","photoUrl":"","userId":"17190914206091993570"}}},"source":["training_args = TrainingArguments(\n","    output_dir=output_dir,                                                                                # output directory\n","    num_train_epochs=epochs,                                                                              # total number of training epochs\n","    per_device_train_batch_size=bs,                                                                       # batch size per device during training\n","    per_device_eval_batch_size=bs,                                                                        # batch size for evaluation\n","    # warmup_steps=warmup_steps,                                                                            # number of warmup steps for learning rate scheduler\n","    weight_decay=0.001,                                                                                   # strength of weight decay\n","    evaluation_strategy=\"epoch\",                                                                          # evaluation interval\n","    logging_dir='./logs',                                                                                 # directory for storing logs\n","    save_strategy=\"epoch\",                                                                                # checkpoint save interval\n","    logging_steps=200,\n",")\n"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"QFdvyS8af-L5","executionInfo":{"status":"ok","timestamp":1630006009004,"user_tz":240,"elapsed":2526,"user":{"displayName":"Kenzo Miranda Sakiyama","photoUrl":"","userId":"17190914206091993570"}}},"source":["trainer = Trainer(\n","    model,\n","    args=training_args,\n","    train_dataset=ds[\"train\"],\n","    eval_dataset=ds[\"test\"],\n","    compute_metrics=compute_metrics,\n","    optimizers=(optimizer, scheduler),\n","    data_collator=collator\n",")"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":999},"id":"jsWGY8XvgC1Y","executionInfo":{"status":"ok","timestamp":1630006815437,"user_tz":240,"elapsed":806458,"user":{"displayName":"Kenzo Miranda Sakiyama","photoUrl":"","userId":"17190914206091993570"}},"outputId":"d8fd8250-cf15-490b-9529-29c330743991"},"source":["trainer.train()"],"execution_count":35,"outputs":[{"output_type":"stream","text":["***** Running training *****\n","  Num examples = 8864\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 64\n","  Total train batch size (w. parallel, distributed & accumulation) = 64\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 695\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='695' max='695' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [695/695 13:25, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.696094</td>\n","      <td>0.706599</td>\n","      <td>0.690701</td>\n","      <td>0.693036</td>\n","      <td>0.684777</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.829000</td>\n","      <td>0.656066</td>\n","      <td>0.728934</td>\n","      <td>0.712552</td>\n","      <td>0.712865</td>\n","      <td>0.711868</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.556600</td>\n","      <td>0.673312</td>\n","      <td>0.729949</td>\n","      <td>0.715815</td>\n","      <td>0.705864</td>\n","      <td>0.708868</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.556600</td>\n","      <td>0.720580</td>\n","      <td>0.727919</td>\n","      <td>0.712686</td>\n","      <td>0.708991</td>\n","      <td>0.710548</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.403600</td>\n","      <td>0.739228</td>\n","      <td>0.725888</td>\n","      <td>0.711149</td>\n","      <td>0.703187</td>\n","      <td>0.705886</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","text":["***** Running Evaluation *****\n","  Num examples = 985\n","  Batch size = 64\n","Saving model checkpoint to /content/drive/MyDrive/Mestrado/transformers/trained_models/bertimbau_tweetsentbr/all_classes/checkpoint-139\n","Configuration saved in /content/drive/MyDrive/Mestrado/transformers/trained_models/bertimbau_tweetsentbr/all_classes/checkpoint-139/config.json\n","Model weights saved in /content/drive/MyDrive/Mestrado/transformers/trained_models/bertimbau_tweetsentbr/all_classes/checkpoint-139/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 985\n","  Batch size = 64\n","Saving model checkpoint to /content/drive/MyDrive/Mestrado/transformers/trained_models/bertimbau_tweetsentbr/all_classes/checkpoint-278\n","Configuration saved in /content/drive/MyDrive/Mestrado/transformers/trained_models/bertimbau_tweetsentbr/all_classes/checkpoint-278/config.json\n","Model weights saved in /content/drive/MyDrive/Mestrado/transformers/trained_models/bertimbau_tweetsentbr/all_classes/checkpoint-278/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 985\n","  Batch size = 64\n","Saving model checkpoint to /content/drive/MyDrive/Mestrado/transformers/trained_models/bertimbau_tweetsentbr/all_classes/checkpoint-417\n","Configuration saved in /content/drive/MyDrive/Mestrado/transformers/trained_models/bertimbau_tweetsentbr/all_classes/checkpoint-417/config.json\n","Model weights saved in /content/drive/MyDrive/Mestrado/transformers/trained_models/bertimbau_tweetsentbr/all_classes/checkpoint-417/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 985\n","  Batch size = 64\n","Saving model checkpoint to /content/drive/MyDrive/Mestrado/transformers/trained_models/bertimbau_tweetsentbr/all_classes/checkpoint-556\n","Configuration saved in /content/drive/MyDrive/Mestrado/transformers/trained_models/bertimbau_tweetsentbr/all_classes/checkpoint-556/config.json\n","Model weights saved in /content/drive/MyDrive/Mestrado/transformers/trained_models/bertimbau_tweetsentbr/all_classes/checkpoint-556/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 985\n","  Batch size = 64\n","Saving model checkpoint to /content/drive/MyDrive/Mestrado/transformers/trained_models/bertimbau_tweetsentbr/all_classes/checkpoint-695\n","Configuration saved in /content/drive/MyDrive/Mestrado/transformers/trained_models/bertimbau_tweetsentbr/all_classes/checkpoint-695/config.json\n","Model weights saved in /content/drive/MyDrive/Mestrado/transformers/trained_models/bertimbau_tweetsentbr/all_classes/checkpoint-695/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=695, training_loss=0.5657369984139642, metrics={'train_runtime': 806.3246, 'train_samples_per_second': 54.965, 'train_steps_per_second': 0.862, 'total_flos': 1204582560124608.0, 'train_loss': 0.5657369984139642, 'epoch': 5.0})"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"AbUmYWu7ltcI","executionInfo":{"status":"ok","timestamp":1630006815440,"user_tz":240,"elapsed":69,"user":{"displayName":"Kenzo Miranda Sakiyama","photoUrl":"","userId":"17190914206091993570"}}},"source":[""],"execution_count":35,"outputs":[]}]}